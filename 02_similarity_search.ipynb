{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import networkx as nx\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"community_graph_embeded.pkl\", \"rb\") as f:\n",
    "    G = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dimension = np.array(G.nodes[0][\"embedding\"]).shape[0]\n",
    "index = faiss.IndexFlatL2(embedding_dimension)\n",
    "index.is_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(868,) (868, 768)\n"
     ]
    }
   ],
   "source": [
    "# embedding matrix 以及对应nodeid matrix\n",
    "ids = np.array([node for node in G.nodes()])\n",
    "node_embeddings = np.array([node['embedding'] for id,node in G.nodes(data=True)])\n",
    "print(ids.shape,node_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "868"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add to index\n",
    "index.add(node_embeddings)\n",
    "index.ntotal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "import json\n",
    "embed_model = OllamaEmbeddings(model='nomic-embed-text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "degree_centralities = nx.degree_centrality(G)\n",
    "\n",
    "# step 1: find nodes with similar profile\n",
    "def semantic_similarity_search(query, k1):\n",
    "    query = str(query)\n",
    "    query_embed = embed_model.embed_query(query)\n",
    "    query_embed = np.array(query_embed).reshape(1,-1)\n",
    "    d, i = index.search(query_embed, k1)\n",
    "    similar_nodes = ids[i][0]\n",
    "    simiilar_scores = d[0]  \n",
    "    return similar_nodes,simiilar_scores\n",
    "\n",
    "# step 2: find nodes with similar degree_centrality in the community network\n",
    "def social_similarity_search(node_id,k2,node_type='Actors'):\n",
    "    # filter all Actor nodes\n",
    "    same_type_nodes = [node for node in G.nodes() if G.nodes[node][\"type\"] == node_type]\n",
    "    node_degree_centrality = degree_centralities[node_id]\n",
    "    node_degree_centralities = {k:abs(v-node_degree_centrality) for k, v in degree_centralities.items() if k in same_type_nodes}\n",
    "    sorted_nodes = sorted(node_degree_centralities.items(), key=lambda x: x[1])\n",
    "    sorted_similar_nodes = sorted_nodes[:k2]\n",
    "    similar_nodes = [node for node, _ in sorted_similar_nodes]\n",
    "    similar_scores = [score for _, score in sorted_similar_nodes]\n",
    "    return similar_nodes,similar_scores\n",
    "\n",
    "# combine the two similarity search results\n",
    "def combined_search(query, k1=5, k2=2, type='Actors'):\n",
    "    nodes = []\n",
    "    scores = []\n",
    "    senmantic_similar_nodes,senmantic_similar_scores = semantic_similarity_search(query, k1)\n",
    "    for node1,score1 in zip(senmantic_similar_nodes,senmantic_similar_scores):\n",
    "        social_similar_nodes,social_similar_scores = social_similarity_search(node1,k2)\n",
    "        filtered_nodes = [n for n in social_similar_nodes if n not in nodes]\n",
    "        filtered_scores = [score1+score2 for score2,n in zip(social_similar_scores,social_similar_nodes) if n not in nodes]\n",
    "        nodes.extend(filtered_nodes)\n",
    "        scores.extend(filtered_scores)\n",
    "    return nodes,scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_input = {\n",
    "'age': '18-35',\n",
    "'gender': 'Female',\n",
    "'marrige': 'Yes',\n",
    "'withkids': 'No',\n",
    "'student': 'Yes',\n",
    "'workstatue': 'Freelancer',\n",
    "'residentinneighbor': 'No',\n",
    "'educationlevel': 'Undergraduate'\n",
    "}\n",
    "k1 = 5\n",
    "k2 = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "semantic_similarity_search: [ 267  768 1054  231  268] [0.49987638 0.6176311  0.6176311  0.6176311  0.6176311 ]\n"
     ]
    }
   ],
   "source": [
    "similar_nodes,simiilar_scores = semantic_similarity_search(example_input, k1)\n",
    "print(\"semantic_similarity_search:\",similar_nodes,simiilar_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar nodes:  [12, 469, 457, 768, 686, 702, 681, 464]\n",
      "Scores:  [0.49987637996673584, 0.49987637996673584, 0.6176310777664185, 0.6176310777664185, 0.6176310777664185, 0.6176310777664185, 0.6176310777664185, 0.6176310777664185]\n"
     ]
    }
   ],
   "source": [
    "nodes,scores = combined_search(example_input, k1, k2)\n",
    "print(\"Similar nodes: \", nodes) \n",
    "print(\"Scores: \", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
